# Training parameters
num_epochs: 30
tokens_per_epoch: 134217728 # 1024*1024*16 # 201326592 # 1024*1024*192
tokens_per_step: 16384 # 1024 * 16
# mini_batch_size: 2
max_length: 4096

limit_num_of_samples: null # 200000

learning_rate: 2e-5 # 5e-4 # 2e-5 # 
constant_lr: True
weight_decay: 0.1
logging_steps: 1

train_on_cots: True
use_wait: False
use_aha: False

redundacy: 0
p_redundancy: 0.0
percentage_misplaced_keywords: 0.0

temperature: 0.0

# Path to checkpoint directory to resume training from, null means start from scratch
resume_from_checkpoint: null