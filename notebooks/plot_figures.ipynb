{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2718e-2224-4dea-8653-37c04efd6cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:24:54.544023Z",
     "start_time": "2025-05-15T09:24:54.541032Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48276c4-1d5d-4a1f-90fd-f3f170f5ec78",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43a3d6-8765-4b02-8c1d-b3c134930685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:24:54.948840Z",
     "start_time": "2025-05-15T09:24:54.946868Z"
    }
   },
   "outputs": [],
   "source": [
    "COLOR_P5 = \"#D55E00\"\n",
    "COLOR_P5 = \"#C51B00\" \n",
    "COLOR_N5 = \"#0072B2\"\n",
    "COLOR_ZERO = \"#009E73\"\n",
    "COLOR_QA = \"#000000\"\n",
    "COLOR_P5_STOCH = \"#E69F00\"\n",
    "COLOR_P5_DET = \"#56B4E9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c39e7f-b733-4ca2-a218-72d5c039a688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:24:55.275699Z",
     "start_time": "2025-05-15T09:24:55.270350Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_simulation_runs(csv_paths):\n",
    "    \"\"\"\n",
    "    Calculate average and standard deviation for each checkpoint across multiple simulation runs.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_paths (list): List of paths to CSV files\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with columns 'mean' and 'std' for each metric,\n",
    "                     indexed by row number (checkpoint position)\n",
    "    \"\"\"\n",
    "    # Read all CSV files\n",
    "    dataframes = []\n",
    "    for path in csv_paths:\n",
    "        df = pd.read_csv(path)\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Check that all dataframes have the same number of rows\n",
    "    num_rows = len(dataframes[0])\n",
    "    if not all(len(df) == num_rows for df in dataframes):\n",
    "        raise ValueError(\"All CSV files must have the same number of rows\")\n",
    "    \n",
    "    # Get column names (excluding checkpoint column if present)\n",
    "    # Assuming the first column might be checkpoint/step/iteration\n",
    "    columns = dataframes[0].columns.tolist()\n",
    "    \n",
    "    # If there's a column that looks like checkpoint/step/iteration, exclude it\n",
    "    checkpoint_cols = ['checkpoint', 'step', 'iteration', 'epoch']\n",
    "    data_columns = [col for col in columns \n",
    "                   if col.lower() not in checkpoint_cols and not col.lower().startswith('step')]\n",
    "    \n",
    "    # If no data columns identified, use all columns except the first one\n",
    "    if not data_columns:\n",
    "        data_columns = columns[1:] if len(columns) > 1 else columns\n",
    "    \n",
    "    # Create result dictionary to store mean and std for each metric\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate mean and std for each metric across all runs\n",
    "    for col in data_columns:\n",
    "        # Extract column values from all dataframes\n",
    "        col_data = np.array([df[col].values for df in dataframes])\n",
    "        \n",
    "        # Calculate mean and std across runs (axis=0)\n",
    "        col_mean = np.mean(col_data, axis=0)\n",
    "        col_std = np.std(col_data, axis=0)\n",
    "        \n",
    "        results[f'{col}_mean'] = col_mean\n",
    "        results[f'{col}_std'] = col_std\n",
    "    \n",
    "    # Create result dataframe\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.index.name = 'checkpoint_position'\n",
    "    \n",
    "    # Optionally, add average checkpoint value if checkpoint column exists\n",
    "    checkpoint_col = None\n",
    "    for col in columns:\n",
    "        if col.lower() in checkpoint_cols or col.lower().startswith('step'):\n",
    "            checkpoint_col = col\n",
    "            break\n",
    "    \n",
    "    if checkpoint_col:\n",
    "        checkpoint_values = np.array([df[checkpoint_col].values for df in dataframes])\n",
    "        avg_checkpoint = np.mean(checkpoint_values, axis=0)\n",
    "        result_df.insert(0, 'avg_checkpoint_value', avg_checkpoint)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f3580-00ad-4a01-b965-5e1907dc3401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:24:55.797403Z",
     "start_time": "2025-05-15T09:24:55.788837Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "def plot_with_error_bars_multi(\n",
    "    stats_dfs: Sequence[pd.DataFrame],\n",
    "    metric_names=(\"is_A_path_correct\", \"Answer Accuracy\"),\n",
    "    divide_metric=None,\n",
    "    names=None,\n",
    "    figsize=(3.0, 2.5),\n",
    "    dpi=300,\n",
    "    error_bar_interval=1,\n",
    "    ylabel=None,\n",
    "    loc=\"lower right\",\n",
    "    palette=None,\n",
    "    line_colors=None,\n",
    "    line_styles=None,\n",
    "    show_legend=True,\n",
    "    use_fill_between=False,\n",
    "    xlim=None,\n",
    "    ylim=None,\n",
    "    highlight_max=False,\n",
    "    max_marker=\"*\",\n",
    "    max_marker_size=100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot mean ± 1 σ curves for one **or many** metrics across several runs,\n",
    "    optionally dividing each metric by an additional “denominator” metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stats_dfs : list[pandas.DataFrame]\n",
    "        Each DataFrame must contain columns `<metric>_mean` and `<metric>_std`\n",
    "        for **every** metric passed in `metric_names`, plus for `divide_metric` if specified.\n",
    "    metric_names : tuple[str, str] or list[tuple[str, str]]\n",
    "        Single `(column_base, pretty_name)` or list of such pairs for multi‐metric plots.\n",
    "    divide_metric : tuple[str, str] or None\n",
    "        If provided, a `(column_base, pretty_name)` pair. Each main metric's mean\n",
    "        will be divided by this metric's mean, and its std propagated:\n",
    "            R = A / B,\n",
    "            σ_R = R * sqrt((σ_A/A)² + (σ_B/B)²).\n",
    "    names : list[str] or None\n",
    "        Labels for the runs. When multiple metrics are requested, each legend entry\n",
    "        becomes \"{run label} – {metric pretty_name}\".\n",
    "    figsize, dpi : tuple, int\n",
    "        Matplotlib figure size and resolution.\n",
    "    error_bar_interval : int, default 1\n",
    "        Plot an error bar every *n* points along the curve (ignored if `use_fill_between=True`).\n",
    "    ylabel : str or None\n",
    "        Label for the y‐axis. If None, the first metric's pretty name is used.\n",
    "    loc : str\n",
    "        Location of the legend (matplotlib location code).\n",
    "    palette : list/tuple or None\n",
    "        List of colours. Used if `line_colors` is not provided.\n",
    "    line_colors : list or None\n",
    "        Overrides `palette` if provided.\n",
    "    line_styles : list or None\n",
    "        List of matplotlib linestyles for each line.\n",
    "    show_legend : bool, default True\n",
    "        Whether to display the legend.\n",
    "    use_fill_between : bool, default False\n",
    "        If True, shade the 1σ band instead of plotting error bars.\n",
    "    ylim : tuple or None\n",
    "        Tuple (ymin, ymax) to set the y‐axis limits explicitly.\n",
    "    highlight_max : bool, default False\n",
    "        If True, truncate each curve at its maximum and place a star marker there.\n",
    "    max_marker : str, default \"*\"\n",
    "        Marker style for the maximum point.\n",
    "    max_marker_size : int, default 100\n",
    "        Marker size (points^2) for the maximum point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax : matplotlib Figure and Axes\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Input validation ------------------------------------------------\n",
    "    if not isinstance(stats_dfs, (list, tuple)):\n",
    "        raise TypeError(\"stats_dfs must be a list or tuple of DataFrames.\")\n",
    "\n",
    "    # Normalize metric_names to a list of tuples\n",
    "    if isinstance(metric_names[0], str):\n",
    "        metric_names = [metric_names]\n",
    "    n_metrics = len(metric_names)\n",
    "\n",
    "    # Normalize divide_metric\n",
    "    if divide_metric is not None:\n",
    "        if not (isinstance(divide_metric, (list, tuple)) and len(divide_metric) == 2):\n",
    "            raise ValueError(\"`divide_metric` must be a (column_base, pretty_name) tuple.\")\n",
    "        denom_base, denom_display = divide_metric\n",
    "\n",
    "    n_runs = len(stats_dfs)\n",
    "    if names is None:\n",
    "        names = [\"\" for _ in range(n_runs)]\n",
    "    elif len(names) != n_runs:\n",
    "        raise ValueError(\"`names` must have the same length as `stats_dfs`.\")\n",
    "\n",
    "    # ---------- Palette/Color handling ------------------------------------------------\n",
    "    total_lines = n_runs * n_metrics\n",
    "    if line_colors is not None:\n",
    "        if len(line_colors) != total_lines:\n",
    "            raise ValueError(\n",
    "                \"`line_colors` must have length equal to number of runs * number of metrics.\"\n",
    "            )\n",
    "        palette = line_colors\n",
    "    elif palette is None or len(palette) < total_lines:\n",
    "        palette = sns.color_palette(\"deep\", n_colors=total_lines)\n",
    "\n",
    "    # ---------- Line style handling ---------------------------------------------------\n",
    "    if line_styles is None:\n",
    "        line_styles = [\"-\"] * total_lines\n",
    "    elif len(line_styles) != total_lines:\n",
    "        raise ValueError(\n",
    "            \"`line_styles` must have length equal to number of runs * number of metrics.\"\n",
    "        )\n",
    "\n",
    "    # ---------- Plotting --------------------------------------------------------\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    colour_idx = 0\n",
    "    for run_idx, (df, run_label) in enumerate(zip(stats_dfs, names)):\n",
    "        # validate denominator columns once per run\n",
    "        if divide_metric is not None:\n",
    "            denom_mean_col = f\"{denom_base}_mean\"\n",
    "            denom_std_col = f\"{denom_base}_std\"\n",
    "            if denom_mean_col not in df or denom_std_col not in df:\n",
    "                raise KeyError(\n",
    "                    f\"DataFrame {run_idx} lacks columns '{denom_mean_col}' and/or '{denom_std_col}'.\"\n",
    "                )\n",
    "            denom_mean = df[denom_mean_col].values\n",
    "            denom_std = df[denom_std_col].values\n",
    "\n",
    "        for metric_idx, (metric_base, metric_display) in enumerate(metric_names):\n",
    "            mean_col = f\"{metric_base}_mean\"\n",
    "            std_col = f\"{metric_base}_std\"\n",
    "            if mean_col not in df or std_col not in df:\n",
    "                raise KeyError(\n",
    "                    f\"DataFrame {run_idx} lacks columns '{mean_col}' and/or '{std_col}'.\"\n",
    "                )\n",
    "\n",
    "            x = np.arange(1, len(df) + 1)\n",
    "            y_raw = df[mean_col].values\n",
    "            y_err_raw = df[std_col].values\n",
    "\n",
    "            # ---- apply divide-by-metric if requested ----\n",
    "            if divide_metric is not None:\n",
    "                ratio = y_raw / denom_mean\n",
    "                # propagate std for ratio: σ_R = R * sqrt((σ_A/A)^2 + (σ_B/B)^2)\n",
    "                y_err = ratio * np.sqrt((y_err_raw / y_raw) ** 2 + (denom_std / denom_mean) ** 2)\n",
    "                y = ratio\n",
    "            else:\n",
    "                y = y_raw\n",
    "                y_err = y_err_raw\n",
    "\n",
    "            # Determine truncation index if highlighting max\n",
    "            if highlight_max:\n",
    "                max_idx = int(np.nanargmax(y))\n",
    "                plot_x = x[: max_idx + 1]\n",
    "                plot_y = y[: max_idx + 1]\n",
    "                plot_y_err = y_err[: max_idx + 1]\n",
    "            else:\n",
    "                plot_x, plot_y, plot_y_err = x, y, y_err\n",
    "                max_idx = None\n",
    "\n",
    "            color = palette[colour_idx]\n",
    "            linestyle = line_styles[colour_idx]\n",
    "            colour_idx += 1\n",
    "\n",
    "            # Line plot\n",
    "            ax.plot(\n",
    "                plot_x,\n",
    "                plot_y,\n",
    "                linestyle=linestyle,\n",
    "                color=color,\n",
    "                linewidth=1.5,\n",
    "                label=(\n",
    "                    f\"{run_label}{', ' if run_label else ''}\"\n",
    "                    f\"{metric_display}\"\n",
    "                    f\"{f' / {denom_display}' if divide_metric else ''}\"\n",
    "                    if n_metrics > 1 or divide_metric\n",
    "                    else run_label\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # Error representation\n",
    "            if use_fill_between:\n",
    "                ax.fill_between(\n",
    "                    plot_x,\n",
    "                    plot_y - plot_y_err,\n",
    "                    plot_y + plot_y_err,\n",
    "                    color=color,\n",
    "                    alpha=0.3,\n",
    "                    linewidth=0,\n",
    "                )\n",
    "            else:\n",
    "                err_idx = plot_x[::error_bar_interval]\n",
    "                ax.errorbar(\n",
    "                    err_idx,\n",
    "                    plot_y[::error_bar_interval],\n",
    "                    yerr=plot_y_err[::error_bar_interval],\n",
    "                    fmt=\"none\",\n",
    "                    ecolor=color,\n",
    "                    elinewidth=1.5,\n",
    "                    capsize=4,\n",
    "                    capthick=1.5,\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "\n",
    "            # Highlight maximum point\n",
    "            if highlight_max and max_idx is not None:\n",
    "                ax.scatter(\n",
    "                    x[max_idx],\n",
    "                    y[max_idx],\n",
    "                    marker=max_marker,\n",
    "                    color=color,\n",
    "                    s=max_marker_size,\n",
    "                    zorder=3,\n",
    "                )\n",
    "\n",
    "    # ---------- Axes styling ----------------------------------------------------\n",
    "    ax.set_xlabel(\"Epoch\", fontweight=\"bold\")\n",
    "    ax.set_ylabel(\n",
    "        f\"{metric_names[0][1]}{f' / {denom_display}' if divide_metric else ''}\"\n",
    "        if ylabel is None\n",
    "        else ylabel,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    # Auto y-limits for single metric between 0 and 1\n",
    "    if n_metrics == 1 and ylim is None and divide_metric is None:\n",
    "        all_vals = np.concatenate([df[f\"{metric_names[0][0]}_mean\"].values for df in stats_dfs])\n",
    "        if all_vals.min() >= 0 and all_vals.max() <= 1:\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "    elif ylim is None:\n",
    "        ax.set_ylim(auto=True)\n",
    "    else:\n",
    "        ax.set_ylim(ylim)\n",
    "    \n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "\n",
    "    if show_legend:\n",
    "        ax.legend(loc=loc, frameon=True, fancybox=True)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bd299-2cb2-4dcd-82e0-39dc34ffb97c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0a434-a662-4605-a40e-e6c5bd89f9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:27:20.431829Z",
     "start_time": "2025-05-15T09:27:20.226269Z"
    }
   },
   "outputs": [],
   "source": [
    "p5_cot = analyze_simulation_runs([\"checkpoints/p5_cot_ibac_1.csv\", \"checkpoints/p5_cot_ibac_2.csv\", \"checkpoints/p5_cot_ibac_3.csv\", \"checkpoints/p5_cot_ibac_4.csv\",  \"checkpoints/p5_cot_ibac_5.csv\"])\n",
    "n5_cot = analyze_simulation_runs([\"checkpoints/n5_cot_ibac_1.csv\", \"checkpoints/n5_cot_ibac_2.csv\", \"checkpoints/n5_cot_ibac_3.csv\", \"checkpoints/n5_cot_ibac_4.csv\", \"checkpoints/n5_cot_ibac_5.csv\"])\n",
    "qa_cot = analyze_simulation_runs([\"checkpoints/qa_cot_1.csv\", \"checkpoints/qa_cot_2.csv\", \"checkpoints/qa_cot_3.csv\",  \"checkpoints/qa_cot_4.csv\",  \"checkpoints/qa_cot_5.csv\"])\n",
    "\n",
    "p5_tokens = analyze_simulation_runs([\"checkpoints/p5_tokens_ibac_1.csv\", \"checkpoints/p5_tokens_ibac_2.csv\", \"checkpoints/p5_tokens_ibac_3.csv\", \"checkpoints/p5_tokens_ibac_4.csv\", \"checkpoints/p5_tokens_ibac_5.csv\"])\n",
    "n5_tokens = analyze_simulation_runs([\"checkpoints/n5_tokens_ibac_1.csv\", \"checkpoints/n5_tokens_ibac_2.csv\", \"checkpoints/n5_tokens_ibac_3.csv\", \"checkpoints/n5_tokens_ibac_4.csv\", \"checkpoints/n5_tokens_ibac_5.csv\"])\n",
    "zero_tokens = analyze_simulation_runs([\"checkpoints/zero_tokens_ibac_1.csv\", \"checkpoints/zero_tokens_ibac_2.csv\", \"checkpoints/zero_tokens_ibac_3.csv\", \"checkpoints/zero_tokens_ibac_4.csv\", \"checkpoints/zero_tokens_ibac_5.csv\"])\n",
    "zero_tokens_temp_0_5 = analyze_simulation_runs([\"checkpoints/zero_tokens_temp_0_5_ibac_1.csv\", \"checkpoints/zero_tokens_temp_0_5_ibac_2.csv\", \"checkpoints/zero_tokens_temp_0_5_ibac_3.csv\", \"checkpoints/zero_tokens_temp_0_5_ibac_4.csv\", \"checkpoints/zero_tokens_temp_0_5_ibac_5.csv\"])\n",
    "zero_tokens_temp_1_0 = analyze_simulation_runs([\"checkpoints/zero_tokens_temp_1_0_ibac_1.csv\", \"checkpoints/zero_tokens_temp_1_0_ibac_2.csv\", \"checkpoints/zero_tokens_temp_1_0_ibac_3.csv\", \"checkpoints/zero_tokens_temp_1_0_ibac_4.csv\", \"checkpoints/zero_tokens_temp_1_0_ibac_5.csv\"])\n",
    "\n",
    "p5_stoch = analyze_simulation_runs([\"checkpoints/p5_stoch_redundancy_ibac_1.csv\", \"checkpoints/p5_stoch_redundancy_ibac_2.csv\", \"checkpoints/p5_stoch_redundancy_ibac_3.csv\", \"checkpoints/p5_stoch_redundancy_ibac_4.csv\", \"checkpoints/p5_stoch_redundancy_ibac_5.csv\"])\n",
    "p5_stoch_temp = analyze_simulation_runs([\"checkpoints/p5_stoch_redundancy_ibac_1_temp_1_0.csv\", \"checkpoints/p5_stoch_redundancy_ibac_2_temp_1_0.csv\", \"checkpoints/p5_stoch_redundancy_ibac_3_temp_1_0.csv\", \"checkpoints/p5_stoch_redundancy_ibac_4_temp_1_0.csv\", \"checkpoints/p5_stoch_redundancy_ibac_5_temp_1_0.csv\"])\n",
    "p5_det = analyze_simulation_runs([\"checkpoints/p5_det_redundancy_ibac_1.csv\", \"checkpoints/p5_det_redundancy_ibac_2.csv\", \"checkpoints/p5_det_redundancy_ibac_3.csv\", \"checkpoints/p5_det_redundancy_ibac_4.csv\", \"checkpoints/p5_det_redundancy_ibac_5.csv\"])\n",
    "\n",
    "zero_32_tokens = analyze_simulation_runs([\"checkpoints/zero_32M_tokens_ibac_1.csv\",\"checkpoints/zero_32M_tokens_ibac_2.csv\", \"checkpoints/zero_32M_tokens_ibac_3.csv\", \"checkpoints/zero_32M_tokens_ibac_4.csv\", \"checkpoints/zero_32M_tokens_ibac_5.csv\"])\n",
    "n5_32_tokens = analyze_simulation_runs([\"checkpoints/n5_32M_tokens_ibac_1.csv\", \"checkpoints/n5_32M_tokens_ibac_2.csv\", \"checkpoints/n5_32M_tokens_ibac_3.csv\", \"checkpoints/n5_32M_tokens_ibac_4.csv\", \"checkpoints/n5_32M_tokens_ibac_5.csv\"])\n",
    "p5_32_tokens = analyze_simulation_runs([\"checkpoints/p5_32M_tokens_ibac_1.csv\", \"checkpoints/p5_32M_tokens_ibac_2.csv\", \"checkpoints/p5_32M_tokens_ibac_3.csv\", \"checkpoints/p5_32M_tokens_ibac_4.csv\", \"checkpoints/p5_32M_tokens_ibac_5.csv\"])\n",
    "\n",
    "p5_32M_tokens_3_layers_scheduler = analyze_simulation_runs([\"checkpoints/p5_32M_tokens_3_layers_scheduler_1.csv\", \"checkpoints/p5_32M_tokens_3_layers_scheduler_2.csv\", \"checkpoints/p5_32M_tokens_3_layers_scheduler_3.csv\"])\n",
    "p5_32M_tokens_6_layers_scheduler = analyze_simulation_runs([\"checkpoints/p5_32M_tokens_6_layers_scheduler_1.csv\", \"checkpoints/p5_32M_tokens_6_layers_scheduler_2.csv\", \"checkpoints/p5_32M_tokens_6_layers_scheduler_3.csv\"])\n",
    "p5_16M_tokens_3_layers_scheduler = analyze_simulation_runs([\"checkpoints/p5_16M_tokens_3_layers_scheduler_1.csv\", \"checkpoints/p5_16M_tokens_3_layers_scheduler_2.csv\", \"checkpoints/p5_16M_tokens_3_layers_scheduler_3.csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f68503-3567-452b-88f7-98dd6d5398b2",
   "metadata": {},
   "source": [
    "## p5 vs n5 200k CoT is_A_path_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4b56a-beb9-41d3-83ea-c0125a780934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:17:32.696308Z",
     "start_time": "2025-05-14T22:17:32.581490Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_cot, p5_cot], names=[r\"$\\eta=-5$\", r\"$\\eta=+5$\"], line_colors=[COLOR_N5, COLOR_P5], use_fill_between=True, show_legend=False, highlight_max=True)\n",
    "fig.savefig('p5_n5_path_correctness_200k_fig1.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8e719-13ca-4ebb-b864-24cdedd24cb1",
   "metadata": {},
   "source": [
    "## p5 vs n5 200k CoT confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df2094-4d32-4bcb-bfd6-47957fe17055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:17:48.041005Z",
     "start_time": "2025-05-14T22:17:47.917177Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([p5_cot, n5_cot], names=[r\"Efficient Trace\", r\"Inefficient Trace\", ], metric_names=(\"avg_prob_1\", \"Next-Token Confidence\"), use_fill_between=True, line_colors=[COLOR_P5, COLOR_N5], ylim=(0.7, 1.0), show_legend=True)\n",
    "fig.savefig('p5_n5_token_confidence_128M_fig1.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebcc94-ccb0-44b9-ad38-fa462f14724a",
   "metadata": {},
   "source": [
    "## p5 vs QA 350k CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb89a5397fd5730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:42:17.977738Z",
     "start_time": "2025-05-15T09:42:17.974416Z"
    }
   },
   "outputs": [],
   "source": [
    "ORANGE=   \"#E69F00\"  # orange\n",
    "SKYBLUE=    \"#56B4E9\"  # sky-blue\n",
    "BG =    \"#009E73\"  # bluish-green\n",
    "YEL =    \"#F0E442\"  # yellow\n",
    "BLUE =    \"#0072B2\"  # blue\n",
    "VERMIL=   \"#D55E00\"  # vermilion\n",
    "REDPURP=    \"#CC79A7\"  # reddish-purple\n",
    "BLACK=    \"#000000\"  # black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9319bda-a63d-431d-8e0d-8a7078e9e917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:42:18.527983Z",
     "start_time": "2025-05-15T09:42:18.408124Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plot_with_error_bars_multi([qa_cot, p5_tokens], \n",
    "                                     names=[r\"QA\", r\"$\\eta=+5$\"],\n",
    "                                     line_colors=[\"#5D6D7E\", \"#8E44AD\", \"#CC79A7\", \"#5D6D7E\", \"#8E44AD\", \"#CC79A7\"],\n",
    "                                     metric_names=[(\"is_A_path_correct_l3\", r\"$d=3$\"), (\"is_A_path_correct_l5\", r\"$d=5$\"), (\"is_A_path_correct_l7\", r\"$d=7$\")],\n",
    "                                     ylabel=\"Answer Accuracy\", use_fill_between=True, show_legend=False,\n",
    "                                     line_styles=[\"--\",\"--\",\"--\",\"-\",\"-\",\"-\"], xlim=(0, 25)\n",
    "                                    )\n",
    "legend_labels = ['graph depth 3', 'graph depth 5', 'graph depth 7']\n",
    "legend_colors = ['#5D6D7E', '#8E44AD', '#CC79A7']\n",
    "    \n",
    "# Create patches (squares) for each legend entry\n",
    "patches = [\n",
    "    mpatches.Rectangle((0, 0), 1, 1, facecolor=color, edgecolor='black', linewidth=0.5, label=label)\n",
    "    for label, color in zip(legend_labels, legend_colors)\n",
    "]\n",
    "\n",
    "# Add the custom legend\n",
    "custom_legend = ax.legend(\n",
    "    handles=patches,\n",
    "    loc=\"lower right\",\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    title=None,\n",
    "    handlelength=1.0,\n",
    "    handleheight=1.0\n",
    ")\n",
    "fig.savefig('p5_qa_350k_fig2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985b0c5-905a-4a39-aa7a-d445f952695e",
   "metadata": {},
   "source": [
    "## p5 128M submetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23339d11-4638-4b63-ac69-93dc61301676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:39:05.957562Z",
     "start_time": "2025-05-15T07:39:05.677838Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([p5_tokens], \n",
    "                                     metric_names=[(\"is_A_path_correct\", \"path optimal\"), (\"is_A_path_possible\", \"path possible\"), (\"is_A_cost_consistent\", \"cost consistent\"), (\"is_A_cost_optimal\", \"cost optimal\")],\n",
    "                                     ylabel=\"\", show_legend=True, use_fill_between=True,\n",
    "                                     line_colors=[COLOR_P5, \"#E69F00\", \"green\", COLOR_N5],\n",
    "                                    )\n",
    "fig.savefig('p5_tokens_submetrics_fig2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8f1ea-c470-40fa-9d1e-80a2784dad5c",
   "metadata": {},
   "source": [
    "## Cost analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286b1a2b50f1a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:57:31.881201Z",
     "start_time": "2025-05-15T07:57:31.874136Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm, colors\n",
    "base = cm.get_cmap('YlGnBu_r', 256)          # 256-level version\n",
    "# Keep only the upper 80 % of the map (0.2 → 1.0)\n",
    "trim = colors.LinearSegmentedColormap.from_list(\n",
    "        'YlGnBu_r_trim', base(np.linspace(0.2, 1.0, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306998a-a84d-4a05-b49d-da7e322e5646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:58:54.324995Z",
     "start_time": "2025-05-15T07:58:54.305993Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Sequence, Optional, Union\n",
    "\n",
    "def plot_accuracy_heatmaps(\n",
    "    tables: Sequence[Union[np.ndarray, pd.DataFrame]],\n",
    "    titles: Optional[Sequence[str]] = None,\n",
    "    figsize=(4.0, 4.0),\n",
    "    dpi=300,\n",
    "    cmap='viridis',\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    xlabel='Addend',\n",
    "    ylabel='Addend',\n",
    "    font_scale: float = 1.0,\n",
    "    label_fontsize: Optional[float] = None,\n",
    "    title_fontsize: Optional[float] = None,\n",
    "    cbar_label: str = \"Accuracy\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot an arbitrary number of accuracy tables side by side as heatmaps\n",
    "    with unified x-axis labels and consistent font sizing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tables : sequence of 2D arrays or DataFrames\n",
    "        Your accuracy matrices. Length must be >= 1.\n",
    "    titles : sequence of str, optional\n",
    "        Titles for each subplot. Defaults to ['Table 1', 'Table 2', ...].\n",
    "    figsize : tuple\n",
    "        Overall figure size.\n",
    "    dpi : int\n",
    "        Figure resolution.\n",
    "    cmap : str\n",
    "        Matplotlib colormap.\n",
    "    vmin, vmax : float\n",
    "        Value range for the color scaling.\n",
    "    xlabel, ylabel : str\n",
    "        Axis labels (ylabel only on leftmost plot, xlabel shown once below all plots).\n",
    "    font_scale : float\n",
    "        Seaborn context font scale to match other plots.\n",
    "    label_fontsize : float, optional\n",
    "        Explicit font size for axis & tick labels (overrides font_scale if provided).\n",
    "    title_fontsize : float, optional\n",
    "        Explicit font size for titles (overrides font_scale if provided).\n",
    "    cbar_label : str\n",
    "        Label for the colorbar.\n",
    "    Returns\n",
    "    -------\n",
    "    fig, axes : matplotlib Figure and list of Axes\n",
    "    \"\"\"\n",
    "    n = len(tables)\n",
    "    if n < 1:\n",
    "        raise ValueError(\"Need at least one table to plot.\")\n",
    "    if titles is None:\n",
    "        titles = [f\"Table {i+1}\" for i in range(n)]\n",
    "    if len(titles) != n:\n",
    "        raise ValueError(\"`titles` must have the same length as `tables`.\")\n",
    "\n",
    "    # Font sizes\n",
    "    base_label_fs = label_fontsize or (font_scale * plt.rcParams['axes.labelsize'])\n",
    "    base_title_fs = title_fontsize or (font_scale * plt.rcParams['axes.titlesize'])\n",
    "    tick_fs = int(font_scale) * plt.rcParams['xtick.labelsize']\n",
    "\n",
    "    # Convert inputs to arrays\n",
    "    mats = [df.values if isinstance(df, pd.DataFrame) else df for df in tables]\n",
    "\n",
    "    # Seaborn styling\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=font_scale)\n",
    "\n",
    "    # Create figure & axes\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=n,\n",
    "        figsize=figsize,\n",
    "        dpi=dpi,\n",
    "        gridspec_kw={'wspace': 0.05},\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    # if only one axis, wrap it\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Turn off major gridlines\n",
    "    for ax in axes:\n",
    "        ax.grid(False, which=\"major\")\n",
    "\n",
    "    # Plot each heatmap\n",
    "    for idx, (ax, mat, title) in enumerate(zip(axes, mats, titles)):\n",
    "        im = ax.imshow(mat, cmap=cmap, vmin=vmin, vmax=vmax, interpolation='nearest')\n",
    "\n",
    "        rows, cols = mat.shape\n",
    "        # X ticks & labels on every plot\n",
    "        ax.set_xticks(np.arange(cols))\n",
    "        ax.set_xticklabels([str(i+1) for i in range(cols)],\n",
    "                           fontweight=\"bold\", fontsize=tick_fs)\n",
    "\n",
    "        # Y ticks & ylabel only on first plot\n",
    "        if idx == 0:\n",
    "            ax.set_yticks(np.arange(rows))\n",
    "            ax.set_yticklabels([str(i) for i in range(rows)],\n",
    "                               fontweight=\"bold\", fontsize=tick_fs)\n",
    "            ax.set_ylabel(ylabel, fontweight=\"bold\", fontsize=base_label_fs)\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Minor gridlines between cells\n",
    "        ax.set_xticks(np.arange(cols+1)-0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(rows+1)-0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=2)\n",
    "        ax.tick_params(which=\"minor\", length=0)\n",
    "\n",
    "        # Title\n",
    "        ax.set_title(title, fontweight=\"bold\", fontsize=base_title_fs)\n",
    "\n",
    "    # Shared x-axis label\n",
    "    fig.supxlabel(xlabel, fontweight=\"bold\", fontsize=base_label_fs)\n",
    "\n",
    "    # Shared colorbar on the right\n",
    "    cbar = fig.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel(cbar_label, rotation=-90, va=\"bottom\",\n",
    "                       fontweight=\"bold\", fontsize=base_label_fs)\n",
    "    cbar.ax.tick_params(labelsize=tick_fs)\n",
    "\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918b90a-3159-4d90-a50f-782e38516231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T07:58:55.758963Z",
     "start_time": "2025-05-15T07:58:54.860937Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "acc1 = pd.read_csv(\"checkpoints/p5_tokens__ibac_1_epoch_1_accuracy_table.csv\").iloc[:, 1:]\n",
    "acc2 = pd.read_csv(\"checkpoints/p5_tokens__ibac_1_epoch_2_accuracy_table.csv\").iloc[:, 1:]\n",
    "acc3 = pd.read_csv(\"checkpoints/p5_tokens__ibac_1_epoch_4_accuracy_table.csv\").iloc[:, 1:]\n",
    "\n",
    "fig, axes = plot_accuracy_heatmaps(\n",
    "    tables=[acc1, acc2, acc3],\n",
    "    titles=[\"Epoch 1\", \"Epoch 2\", \"Epoch 4\"],\n",
    "    title_fontsize=16.0,\n",
    "    label_fontsize=18.0,\n",
    ")\n",
    "fig.savefig('p5_cost_accuracy_fig2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89aa0c9-df5d-4b4a-8eca-715b3796b41c",
   "metadata": {},
   "source": [
    "## n_CoT_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79056498-7b26-4389-8f4d-65ed82706af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:27:14.016512Z",
     "start_time": "2025-05-14T22:27:13.686792Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([zero_tokens, zero_tokens_temp_0_5, zero_tokens_temp_1_0], \n",
    "                                     names=[r\"T=0\", r\"T=0.5\", r\"T=1.0\"],\n",
    "                                     metric_names=[(\"n_CoT_steps\", \"CoT steps\")],\n",
    "                                     loc=\"upper right\", show_legend=True, use_fill_between=True,\n",
    "                                     line_colors=[COLOR_ZERO, COLOR_ZERO, COLOR_ZERO],\n",
    "                                     line_styles=[\"-\", \"--\", \":\"]\n",
    "                                    )\n",
    "ax.set_ylim(20, 80)\n",
    "\n",
    "y_vals = [33, 43, 58]\n",
    "adjs = [5, 4, 5]\n",
    "labels = [r\"$\\eta=+5$\", r\"$\\eta=0$\", r\"$\\eta=-5$\"]\n",
    "cs = [COLOR_P5, COLOR_ZERO, COLOR_N5]\n",
    "x_text = ax.get_xlim()[1] # adjust as needed for spacing\n",
    "for y, label, adj, col in zip(y_vals, labels, adjs, cs):\n",
    "    ax.axhline(y, linewidth=1.5, ls=\"--\", alpha=0.5, color=\"black\", zorder=1)\n",
    "    ax.text(\n",
    "        x=x_text + adj,\n",
    "        y=y, \n",
    "        s=label, \n",
    "        color=col,\n",
    "        va='center', \n",
    "        ha='right', \n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "fig.savefig('cot_steps.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([zero_tokens, zero_tokens_temp_0_5, zero_tokens_temp_1_0], \n",
    "                                     names=[r\"T=0\", r\"T=0.5\", r\"T=1.0\"],\n",
    "                                     loc=\"lower right\", show_legend=True, use_fill_between=True,\n",
    "                                     line_colors=[COLOR_ZERO, COLOR_ZERO, COLOR_ZERO],\n",
    "                                     line_styles=[\"-\", \"--\", \":\"]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5989a0-5f14-4b2c-baa6-5e51e5b26854",
   "metadata": {},
   "source": [
    "## 32M tokens v 128M tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fabdf3-6253-4a77-be9a-ca91689b45d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:28:57.482725Z",
     "start_time": "2025-05-15T09:28:57.335516Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, n5_32_tokens, zero_tokens, zero_32_tokens, p5_tokens, p5_32_tokens], names=[r\"$\\eta=-5 128M$\", r\"$\\eta=-5$ 32M T\", r\"$\\eta=0 128M$\", r\"$\\eta=0$ 32M T\", r\"$\\eta=5$\", r\"$\\eta=5$ 32M T\"],\n",
    "line_colors=[COLOR_N5,COLOR_N5,COLOR_ZERO,COLOR_ZERO, COLOR_P5,COLOR_P5,],\n",
    "line_styles=['-', \"--\", \"-\", \"--\", \"-\", \"--\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "highlight_max=True)\n",
    "\n",
    "legend_labels = [r\"$\\eta=-5$\", r\"$\\eta=+5$\", r\"$\\eta=0$\"]\n",
    "legend_colors = [COLOR_N5, COLOR_P5, COLOR_ZERO]\n",
    "    \n",
    "# Create patches (squares) for each legend entry\n",
    "patches = [\n",
    "    mpatches.Rectangle((0, 0), 1, 1, facecolor=color, edgecolor='black', linewidth=0.5, label=label)\n",
    "    for label, color in zip(legend_labels, legend_colors)\n",
    "]\n",
    "\n",
    "# Add the custom legend\n",
    "custom_legend = ax.legend(\n",
    "    handles=patches,\n",
    "    loc=\"lower right\",\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    title=None,\n",
    "    handlelength=1.0,\n",
    "    handleheight=1.0\n",
    ")\n",
    "fig.savefig('n5_p5_zero_32M_128M_fig4.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd0f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:28:29.274483Z",
     "start_time": "2025-05-14T22:28:29.162532Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, zero_tokens, p5_tokens], names=[r\"$\\eta=-5 128M$\", r\"$\\eta=0 128M$\", r\"$\\eta=5$\"],\n",
    "line_colors=[COLOR_N5,COLOR_ZERO,COLOR_P5],\n",
    "line_styles=['-', \"-\", \"-\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "metric_names=[(\"avg_prob_1\", \"Next-Token Confidence\")],\n",
    "ylim=(0.6, 1.0),\n",
    ")\n",
    "fig.savefig('n5_p5_zero_128M_confidence_fig4.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39313964-79b3-4450-9327-0e8480abc408",
   "metadata": {},
   "source": [
    "## Redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948de2a-e26b-41ec-9274-7738274d044c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:29:07.016976Z",
     "start_time": "2025-05-14T22:29:06.902157Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([p5_tokens, p5_stoch, p5_stoch_temp, p5_det], \n",
    "                                     show_legend=False, \n",
    "                                     use_fill_between=True, \n",
    "                                     line_styles=[\"-\", \"-\", \"--\", \"-\"],\n",
    "                                     line_colors=[COLOR_P5, \"#8C4C36\", \"#8C4C36\", \"#E69F00\"]\n",
    "                                     )\n",
    "fig.savefig('redundancy_fig5.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60ee46-da22-42d3-b53e-ee0afc1ab2d8",
   "metadata": {},
   "source": [
    "## train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458c3ae-9daf-4a00-8155-0312313d5f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:29:40.250357Z",
     "start_time": "2025-05-14T22:29:40.223765Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 128M\n",
    "p5_loss_1 = analyze_simulation_runs([\"checkpoints/p5_tokens_1_train_loss.csv\"])\n",
    "p5_loss_2 = analyze_simulation_runs([ \"checkpoints/p5_tokens_2_train_loss.csv\"])\n",
    "p5_loss_3 = analyze_simulation_runs([ \"checkpoints/p5_tokens_3_train_loss.csv\"])\n",
    "p5_loss_4 = analyze_simulation_runs([ \"checkpoints/p5_tokens_4_train_loss.csv\"])\n",
    "p5_loss_5 = analyze_simulation_runs([ \"checkpoints/p5_tokens_5_train_loss.csv\"])\n",
    "\n",
    "n5_loss_1 = analyze_simulation_runs([\"checkpoints/n5_tokens_1_train_loss.csv\"])\n",
    "n5_loss_2 = analyze_simulation_runs([\"checkpoints/n5_tokens_2_train_loss.csv\"])\n",
    "n5_loss_3 = analyze_simulation_runs([\"checkpoints/n5_tokens_3_train_loss.csv\"])\n",
    "n5_loss_4 = analyze_simulation_runs([\"checkpoints/n5_tokens_4_train_loss.csv\"])\n",
    "n5_loss_5 = analyze_simulation_runs([\"checkpoints/n5_tokens_5_train_loss.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86a38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:29:40.678529Z",
     "start_time": "2025-05-14T22:29:40.666188Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(\n",
    "    stats_dfs: Sequence[pd.DataFrame],\n",
    "    metric_names=('is_A_path_correct', 'Answer Correctness'),\n",
    "    names=None,\n",
    "    x_col=\"_step_mean\",              # ← NEW: which column to use for the abscissa\n",
    "    figsize=(3.0, 2.5),\n",
    "    dpi=300,\n",
    "    error_bar_interval=1,\n",
    "    ylabel=None,\n",
    "    loc='lower right',\n",
    "    palette=None,\n",
    "    line_colors=None,\n",
    "    line_styles=None,\n",
    "    show_legend=True,\n",
    "    use_fill_between=False,\n",
    "    no_errorbars=False,\n",
    "    ylim=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot mean ± 1 σ curves for one **or many** metrics across several runs on\n",
    "    LOG–LOG axes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_col : str\n",
    "        Name of the column that contains the x-values (e.g. steps, epochs).\n",
    "        If None, the DataFrame index is used.\n",
    "    \"\"\"\n",
    "    # ---------- Input validation ------------------------------------------------\n",
    "    if not isinstance(stats_dfs, (list, tuple)):\n",
    "        raise TypeError(\"stats_dfs must be a list or tuple of DataFrames.\")\n",
    "\n",
    "    # Normalise `metric_names` → list[(base, pretty)]\n",
    "    if isinstance(metric_names[0], str):\n",
    "        metric_names = [metric_names]\n",
    "    n_metrics = len(metric_names)\n",
    "    n_runs    = len(stats_dfs)\n",
    "\n",
    "    if names is None:\n",
    "        names = [f'Run {i + 1}' for i in range(n_runs)]\n",
    "    elif len(names) != n_runs:\n",
    "        raise ValueError(\"`names` must have the same length as `stats_dfs`.\")\n",
    "\n",
    "    # ---------- Colour & style bookkeeping --------------------------------------\n",
    "    total_lines = n_runs * n_metrics\n",
    "    if line_colors is not None:\n",
    "        if len(line_colors) != total_lines:\n",
    "            raise ValueError(\"`line_colors` length must equal runs × metrics.\")\n",
    "        palette = line_colors\n",
    "    elif palette is None or len(palette) < total_lines:\n",
    "        palette = sns.color_palette('deep', n_colors=total_lines)\n",
    "\n",
    "    if line_styles is None:\n",
    "        line_styles = ['-'] * total_lines\n",
    "    elif len(line_styles) != total_lines:\n",
    "        raise ValueError(\"`line_styles` length must equal runs × metrics.\")\n",
    "\n",
    "    # ---------- Plotting ---------------------------------------------------------\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "\n",
    "    colour_idx = 0\n",
    "    for df, run_label in zip(stats_dfs, names):\n",
    "        # Resolve x values only once per run\n",
    "        x = df[x_col].values if x_col is not None else df.index.values\n",
    "        x = np.array([sum(x[i:i+5]) / len(x[i:i+5]) for i in range(0, len(x), 5)])\n",
    "        lo, hi = 0.0, 20.0   # new range\n",
    "        x  = (x - x.min()) / (x.max() - x.min()) * (hi - lo) + lo\n",
    "        x = x[:20]\n",
    "        for metric_col_base, metric_display in metric_names:\n",
    "            mean_col = f'{metric_col_base}_mean'\n",
    "            std_col  = f'{metric_col_base}_std'\n",
    "            if mean_col not in df or std_col not in df:\n",
    "                raise KeyError(\n",
    "                    f\"DataFrame for '{run_label}' lacks '{mean_col}' and/or '{std_col}'.\"\n",
    "                )\n",
    "            \n",
    "            \n",
    "            y     = df[mean_col].values\n",
    "            y = np.array([sum(y[i:i+5]) / len(y[i:i+5]) for i in range(0, len(y), 5)])[:20] \n",
    "            y_err = df[std_col].values\n",
    "            y_err = np.array([sum(y_err[i:i+5]) / len(y_err[i:i+5]) for i in range(0, len(y_err), 5)])[:20]\n",
    "            color = palette[colour_idx]\n",
    "            style = line_styles[colour_idx]\n",
    "            colour_idx += 1\n",
    "\n",
    "            # main curve\n",
    "            ax.plot(\n",
    "                x, y,\n",
    "                linestyle=style, color=color, linewidth=2.5, alpha=0.7,\n",
    "                label= '_nolegend_'\n",
    "            )\n",
    "\n",
    "            # uncertainty visuals\n",
    "            if not no_errorbars:\n",
    "                if use_fill_between:\n",
    "                    ax.fill_between(\n",
    "                        x, y - y_err, y + y_err,\n",
    "                        color=color, alpha=0.3, linewidth=0\n",
    "                    )\n",
    "                else:\n",
    "                    # integer indices *into the arrays* for error bars\n",
    "                    err_idx = np.arange(len(x))[::error_bar_interval]\n",
    "                    ax.errorbar(\n",
    "                        x[err_idx], y[err_idx], yerr=y_err[err_idx],\n",
    "                        fmt='none', ecolor=color, elinewidth=1.5,\n",
    "                        capsize=4, capthick=1.5, alpha=0.7\n",
    "                    )\n",
    "\n",
    "    # ---------- Axes & legend tweaks --------------------------------------------\n",
    "    ax.set_xlabel('Epoch', fontweight='bold')\n",
    "    ax.set_ylabel(metric_names[0][1] if ylabel is None else ylabel,\n",
    "                  fontweight='bold')\n",
    "    \n",
    "    \n",
    "    from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "    GROUP = 5                 # how many curves per legend entry\n",
    "    if show_legend:\n",
    "        # 1️⃣  collect all real line handles = children with a label\n",
    "        all_lines  = [c for c in ax.get_children() if isinstance(c, plt.Line2D)]\n",
    "        # 2️⃣  bundle every GROUP lines into a tuple\n",
    "        handles = [tuple(all_lines[i:i + GROUP])\n",
    "                   for i in range(0, len(all_lines), GROUP)]\n",
    "        # 3️⃣  pick a label for each bundle\n",
    "        if names and len(names) == len(handles):\n",
    "            labels = names\n",
    "        else:  # fallback: Run 1, Run 2, …\n",
    "            labels = ['$\\eta=5$', '$\\eta=-5$']\n",
    "    \n",
    "        # 4️⃣  build the legend with a handler that can draw tuples\n",
    "        ax.legend(handles=handles,\n",
    "                  labels=labels,\n",
    "                  handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "                  loc=loc, frameon=True, fancybox=True)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206294bf-b36a-4e14-b985-18eb9cff85fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T22:29:42.409618Z",
     "start_time": "2025-05-14T22:29:42.255367Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_loss([p5_loss_1, p5_loss_2, p5_loss_3, p5_loss_4, p5_loss_5, n5_loss_1, n5_loss_2, n5_loss_3, n5_loss_4, n5_loss_5], names=[r\"$\\eta=5$, seed 1\", r\"$\\eta=5$, seed 2\", r\"$\\eta=5$, seed 3\", r\"$\\eta=5$, seed 4\", r\"$\\eta=5$, seed 5\", r\"$\\eta=-5$, seed 1\", r\"$\\eta=-5$, seed 2\", r\"$\\eta=-5$, seed 3\", r\"$\\eta=-5$, seed 4\", r\"$\\eta=-5$, seed 5\"], metric_names=[(\"train/loss\", \"Training loss\")], loc=\"upper right\",\n",
    " use_fill_between=True,\n",
    "show_legend=True,\n",
    "line_colors=[\n",
    "    \"#C51B00\",  # original (seed 1)\n",
    "    \"#A81800\",  # darker red\n",
    "    \"#8C1500\",  # more muted\n",
    "    \"#701200\",  # even darker\n",
    "    \"#541000\",  # darkest shade\n",
    "\n",
    "    \"#0072B2\",  # original (seed 1)\n",
    "    \"#005A8F\",  # darker blue\n",
    "    \"#00426B\",  # more muted\n",
    "    \"#002B48\",  # even darker\n",
    "    \"#001324\",  # darkest shade\n",
    "],)\n",
    "fig.savefig('./n5_p5_128M_train_loss_fig4.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59806a5",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f09450",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"repeated_CoT_steps\", \"repeated_CoT_steps\")],\n",
    "divide_metric=(\"n_CoT_steps\", \"cot steps\"),\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_repeated_cot_steps_perc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"sub_prob_optimal_CoT_steps\", \"sub_prob_optimal_CoT_steps\")],\n",
    "divide_metric=(\"n_CoT_steps\", \"cot steps\"),\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_sub_prob_optimal_perc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"consistent_CoT_steps\", \"consistent_CoT_steps\")],\n",
    "divide_metric=(\"n_CoT_steps\", \"cot steps\"),\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_consistent_cot_steps_perc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fef111",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"CoT_path_possible\", \"CoT_path_possible\")],\n",
    "divide_metric=(\"n_CoT_steps\", \"cot steps\"),\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_cot_path_possible.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9eb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"CoT_steps_skipped_sub_prob\", \"CoT_steps_skipped_sub_prob\")],\n",
    "divide_metric=(\"n_CoT_steps\", \"cot steps\"),\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_cot_steps_skipped.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([n5_tokens, p5_tokens], names=[r\"$\\eta=-5$\", r\"$\\eta=5$\"],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_N5,COLOR_P5],\n",
    "metric_names=[(\"syntax_errors\", \"syntax_errors\")],\n",
    "ylabel=\"\",\n",
    ")\n",
    "fig.savefig('n5_p5_syntax_errors.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "def plot_histograms(\n",
    "    data: Sequence[pd.Series] | Sequence[np.ndarray],\n",
    "    labels=None,\n",
    "    bins=30,\n",
    "    density=False,\n",
    "    cumulative=False,\n",
    "    figsize=(3.0, 2.5),\n",
    "    dpi=300,\n",
    "    palette=None,\n",
    "    colors=None,\n",
    "    alpha=0.6,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.0,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    title=None,\n",
    "    loc=\"upper right\",\n",
    "    show_legend=True,\n",
    "    ylim=None,\n",
    "    xlim=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot one or more overlaid histograms with y-axis shown as percentages.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list of pandas.Series or numpy.ndarray\n",
    "        Each element provides the values to histogram. All series will be overlaid.\n",
    "    labels : list[str] or None\n",
    "        Legend labels for each dataset.\n",
    "    bins : int or sequence, default 30\n",
    "        Number of bins (or explicit bin edges) for the histograms.\n",
    "    density : bool, default False\n",
    "        If True, show probability density instead of counts (in which case y-axis percentages are of density values).\n",
    "    cumulative : bool, default False\n",
    "        If True, plot the cumulative histogram.\n",
    "    figsize : tuple(float, float), default (3.0, 2.5)\n",
    "        Figure size in inches.\n",
    "    dpi : int, default 300\n",
    "        Figure resolution.\n",
    "    palette : list or None\n",
    "        A list of colors to cycle through. Ignored if `colors` is provided.\n",
    "    colors : list or None\n",
    "        Explicit list of colors for each histogram. Overrides `palette`.\n",
    "    alpha : float, default 0.6\n",
    "        Transparency for each histogram patch.\n",
    "    edgecolor : str, default \"black\"\n",
    "        Color of the bar edges.\n",
    "    linewidth : float, default 1.0\n",
    "        Width of the bar edges.\n",
    "    xlabel : str or None\n",
    "        Label for the x-axis.\n",
    "    ylabel : str or None\n",
    "        Label for the y-axis. If None, will default to \"%\".\n",
    "    title : str or None\n",
    "        Plot title.\n",
    "    loc : str, default \"upper right\"\n",
    "        Legend location.\n",
    "    show_legend : bool, default True\n",
    "        Whether to draw the legend.\n",
    "    ylim : tuple or None\n",
    "        y-axis limits as (min, max).\n",
    "    xlim : tuple or None\n",
    "        x-axis limits as (min, max).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax : matplotlib Figure and Axes\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(data, (list, tuple)):\n",
    "        raise TypeError(\"`data` must be a list or tuple of arrays or Series.\")\n",
    "    n = len(data)\n",
    "    if labels is None:\n",
    "        labels = [f\"Series {i+1}\" for i in range(n)]\n",
    "    elif len(labels) != n:\n",
    "        raise ValueError(\"`labels` must have the same length as `data`.\")\n",
    "\n",
    "    # Color handling\n",
    "    if colors is not None:\n",
    "        if len(colors) != n:\n",
    "            raise ValueError(\"`colors` must have same length as `data`.\")\n",
    "        palette = colors\n",
    "    elif palette is None or len(palette) < n:\n",
    "        palette = sns.color_palette(\"deep\", n_colors=n)\n",
    "\n",
    "    # Plot setup\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    # Plot each histogram\n",
    "    for i, series in enumerate(data):\n",
    "        arr = np.asarray(series).ravel()\n",
    "        # For raw counts, convert to percent of total; for density, leave as-is\n",
    "        if density:\n",
    "            hist_kwargs = {\"density\": True}\n",
    "        else:\n",
    "            hist_kwargs = {\"weights\": np.ones_like(arr) / arr.size * 100}\n",
    "\n",
    "        ax.hist(\n",
    "            arr,\n",
    "            bins=bins,\n",
    "            cumulative=cumulative,\n",
    "            color=palette[i],\n",
    "            alpha=alpha,\n",
    "            edgecolor=edgecolor,\n",
    "            linewidth=linewidth,\n",
    "            label=labels[i],\n",
    "            **hist_kwargs,\n",
    "        )\n",
    "\n",
    "    # Axes styling\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontweight=\"bold\")\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontweight=\"bold\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"%\", fontweight=\"bold\")\n",
    "    if title:\n",
    "        ax.set_title(title, fontweight=\"bold\")\n",
    "\n",
    "    # Format y-axis labels as percentages\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{x:.0f}%\"))\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    if show_legend:\n",
    "        ax.legend(loc=loc, frameon=True, fancybox=True)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eae6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_steps_n5 = pd.read_csv(\"checkpoints/cot_steps_efficiency_n5.csv\").loc[7:][\"parameter\"].astype(int)\n",
    "cot_steps_p5 = pd.read_csv(\"checkpoints/cot_steps_efficiency_p5.csv\").loc[7:][\"parameter\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_histograms([cot_steps_n5],\n",
    "                          show_legend=False,\n",
    "                          xlabel=\"CoT steps\",\n",
    "                          ylabel=\"occurrences\",\n",
    "                          colors=[COLOR_N5],\n",
    "                          alpha=1.0\n",
    "                          )\n",
    "\n",
    "fig.savefig('cot_steps_n5.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_histograms([cot_steps_p5],\n",
    "                          show_legend=False,\n",
    "                          xlabel=\"CoT steps\",\n",
    "                          ylabel=\"occurrences\",\n",
    "                          colors=[COLOR_P5],\n",
    "                          alpha=1.0\n",
    "                          )\n",
    "\n",
    "fig.savefig('cot_steps_p5.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([p5_32M_tokens_3_layers_scheduler, p5_32M_tokens_6_layers_scheduler],\n",
    "show_legend=False,\n",
    "use_fill_between=True,\n",
    "line_colors=[COLOR_P5,COLOR_P5],\n",
    "line_styles=[\"-\", \"--\"],\n",
    ")\n",
    "fig.savefig('p5_3_6_layers.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982676a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_with_error_bars_multi([p5_16M_tokens_3_layers_scheduler, p5_32M_tokens_3_layers_scheduler],\n",
    "                                     show_legend=False,\n",
    "                                     use_fill_between=True,\n",
    "                                     line_colors=[COLOR_P5,COLOR_P5],\n",
    "                                     line_styles=[\"-.\", \"-\"],\n",
    "                                     )\n",
    "fig.savefig('p5_16M_32M.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table_n5 = pd.read_csv(\"checkpoints/sum_table_n5.csv\").iloc[:, 1:]\n",
    "sum_table_p5 = pd.read_csv(\"checkpoints/sum_table_p5.csv\").iloc[:, 1:]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Sequence, Optional, Union\n",
    "\n",
    "def plot_log1p_heatmaps(\n",
    "    tables: Sequence[Union[np.ndarray, pd.DataFrame]],\n",
    "    titles: Optional[Sequence[str]] = None,\n",
    "    figsize=(3.0, 4.0),\n",
    "    dpi=300,\n",
    "    cmap='viridis',\n",
    "    vmin: Optional[float] = 0.0,\n",
    "    vmax: Optional[float] = None,\n",
    "    xlabel='Addend',\n",
    "    ylabel='Addend',\n",
    "    font_scale: float = 1.0,\n",
    "    label_fontsize: Optional[float] = None,\n",
    "    title_fontsize: Optional[float] = None,\n",
    "    cbar_label: str = \"log(count + 1)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot an arbitrary number of tables of values, but display log(x+1) of\n",
    "    each cell instead of the raw values.\n",
    "\n",
    "    All other styling and layout mirrors the original heatmap function.\n",
    "    \"\"\"\n",
    "    n = len(tables)\n",
    "    if n < 1:\n",
    "        raise ValueError(\"Need at least one table to plot.\")\n",
    "    if titles is None:\n",
    "        titles = [f\"Table {i+1}\" for i in range(n)]\n",
    "    if len(titles) != n:\n",
    "        raise ValueError(\"`titles` must have the same length as `tables`.\")\n",
    "\n",
    "    # Font sizes\n",
    "    base_label_fs = label_fontsize or (font_scale * plt.rcParams['axes.labelsize'])\n",
    "    base_title_fs = title_fontsize or (font_scale * plt.rcParams['axes.titlesize'])\n",
    "    tick_fs       = font_scale * plt.rcParams['xtick.labelsize']\n",
    "\n",
    "    # Convert & transform inputs to arrays via log1p\n",
    "    mats = []\n",
    "    for tbl in tables:\n",
    "        arr = tbl.values if isinstance(tbl, pd.DataFrame) else tbl\n",
    "        mats.append(np.log1p(arr))\n",
    "\n",
    "    # If vmax not set, derive from max(log1p(x)) across all mats\n",
    "    if vmax is None:\n",
    "        vmax = max(mat.max() for mat in mats)\n",
    "\n",
    "    # Seaborn styling\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=font_scale)\n",
    "\n",
    "    # Create figure & axes\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=n,\n",
    "        figsize=figsize,\n",
    "        dpi=dpi,\n",
    "        gridspec_kw={'wspace': 0.05},\n",
    "        constrained_layout=True\n",
    "    )\n",
    "    # normalize axes array\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Turn off major gridlines\n",
    "    for ax in axes:\n",
    "        ax.grid(False, which=\"major\")\n",
    "\n",
    "    # Plot each heatmap\n",
    "    for idx, (ax, mat, title) in enumerate(zip(axes, mats, titles)):\n",
    "        im = ax.imshow(mat, cmap=cmap, vmin=vmin, vmax=vmax, interpolation='nearest')\n",
    "\n",
    "        rows, cols = mat.shape\n",
    "        ax.set_xticks(np.arange(cols))\n",
    "        ax.set_xticklabels([str(i+1) for i in range(cols)],\n",
    "                           fontweight=\"bold\", fontsize=tick_fs)\n",
    "\n",
    "        if idx == 0:\n",
    "            ax.set_yticks(np.arange(rows))\n",
    "            ax.set_yticklabels([str(i) for i in range(rows)],\n",
    "                               fontweight=\"bold\", fontsize=tick_fs)\n",
    "            ax.set_ylabel(ylabel, fontweight=\"bold\", fontsize=base_label_fs)\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Minor gridlines between cells\n",
    "        ax.set_xticks(np.arange(cols+1)-0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(rows+1)-0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=2)\n",
    "        ax.tick_params(which=\"minor\", length=0)\n",
    "\n",
    "        ax.set_title(title, fontweight=\"bold\", fontsize=base_title_fs)\n",
    "\n",
    "    # Shared x-axis label\n",
    "    fig.supxlabel(xlabel, fontweight=\"bold\", fontsize=base_label_fs)\n",
    "\n",
    "    # Shared colorbar on the right\n",
    "    cbar = fig.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel(cbar_label, rotation=-90, va=\"bottom\",\n",
    "                       fontweight=\"bold\", fontsize=base_label_fs)\n",
    "    cbar.ax.tick_params(labelsize=tick_fs)\n",
    "\n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "fig, axes = plot_log1p_heatmaps(\n",
    "    tables=[sum_table_n5, sum_table_p5],\n",
    "    titles=[r\"$\\eta=-5$\", r\"$\\eta=+5$\"],\n",
    "    title_fontsize=16.0,\n",
    "    label_fontsize=18.0,\n",
    ")\n",
    "fig.savefig('sum_table_costs.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33b75d",
   "metadata": {},
   "source": [
    "# Getting losses from wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477909c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70778a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run(f\"[put here run id]\")\n",
    "history = run.history()\n",
    "loss_data = history[[\"_step\", \"train/loss\"]]\n",
    "loss_data.to_csv(\"checkpoints/p5_tokens_3_ibac_train_loss.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
